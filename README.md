# Coherence Diagnostic

Analyse design concepts for coherence. See what's strong, thin, or unclear.

**Part of [Koher](https://koher.app) â€” AI handles language. Code handles judgment. Humans make decisions.**

---

## ðŸš€ Get Started

### Try It Online

**[â†’ Launch Coherence Diagnostic](https://coherence-demo.koher.app)**

Hosted instance available by invitation. [Request access](mailto:hello@koher.app?subject=Coherence%20Diagnostic%20Access%20Request&body=I%27d%20like%20to%20try%20the%20Coherence%20Diagnostic%20tool.)

### Run Locally

```bash
git clone https://github.com/koher-architecture/coherence-diagnostic.git
cd coherence-diagnostic
pip install -r backend/requirements.txt
export ANTHROPIC_API_KEY="your-key-here"
uvicorn backend.main:app --reload
# Open http://localhost:8000
```

Requires Python 3.11+, ~750MB disk (for model weights), and an [Anthropic API key](https://console.anthropic.com/).

---

## What It Does

Paste a design concept. Get a three-state evaluation across five dimensions:

| Dimension | What It Measures |
|-----------|------------------|
| **Claim** | Is there a clear, testable statement? |
| **Evidence** | Is the claim supported by observation or data? |
| **Scope** | Are boundaries defined (who, where, when)? |
| **Assumptions** | Are underlying beliefs acknowledged? |
| **Gaps** | Does reasoning connect problem to solution? |

Each dimension receives one of three states:
- **â— Solid** â€” clearly present
- **â— Worth examining** â€” something there, but vague
- **â—‹ Needs attention** â€” absent or unclear

---

## Architecture

This tool demonstrates the Koher three-layer architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: Qualification                                     â”‚
â”‚  DeBERTa multi-label classifier (98.38% accuracy)           â”‚
â”‚  Input: concept text â†’ Output: confidence scores (0.0â€“1.0)  â”‚
â”‚  Principle: AI reads language patterns                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: Deterministic Rules                               â”‚
â”‚  Pure Python code â€” no AI                                   â”‚
â”‚  Input: confidence scores â†’ Output: severity levels         â”‚
â”‚  Thresholds: >0.8 = SOLID, 0.5â€“0.8 = EXAMINE, <0.5 = ATTENTION â”‚
â”‚  Principle: Code handles judgment                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: Language Interface                                â”‚
â”‚  Claude Haiku explains the judgment                         â”‚
â”‚  Input: severity levels â†’ Output: plain language diagnosis  â”‚
â”‚  Principle: AI narrates decisions already made              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why separate layers?**
- Stage 1 (AI): Good at pattern recognition across language
- Stage 2 (Code): Judgment is auditable, reproducible, explicit
- Stage 3 (AI): Good at narrating decisions already made

When you ask AI to "judge whether this is good," you lose auditability. When you separate the layers, you gain it back.

---

## Running Locally

### Requirements

- Python 3.11+
- ~750MB disk space (for DeBERTa model)
- Anthropic API key (for Stage 3 diagnosis)

### Setup

```bash
# Clone the repository
git clone https://github.com/koher-architecture/coherence-diagnostic.git
cd coherence-diagnostic

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r backend/requirements.txt

# Set your Anthropic API key
export ANTHROPIC_API_KEY="your-key-here"

# Run the server
uvicorn backend.main:app --reload
```

Open `http://localhost:8000` in your browser.

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `ANTHROPIC_API_KEY` | Yes | For Stage 3 diagnosis (Haiku) |
| `DEMO_PASSWORD` | No | Password protection (default: none) |
| `SESSION_SECRET` | No | For signed cookies |

### Docker

```bash
# Build
docker build -t coherence-diagnostic .

# Run
docker run -p 8000:8000 \
  -e ANTHROPIC_API_KEY=your_key \
  -e DEMO_PASSWORD=your_password \
  coherence-diagnostic
```

---

## File Structure

```
coherence-diagnostic/
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ LICENSE                       # MIT
â”œâ”€â”€ Dockerfile                    # Container build
â”œâ”€â”€ captain-definition            # CapRover deployment config
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                   # FastAPI server
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html                # Single-page application
â”œâ”€â”€ src/
â”‚   â””â”€â”€ stage2_rules.py           # Deterministic judgment rules
â””â”€â”€ models/
    â””â”€â”€ deberta-coherence/        # Trained DeBERTa model (~738MB)
        â”œâ”€â”€ model.safetensors
        â”œâ”€â”€ config.json
        â””â”€â”€ ...
```

---

## The Five Dimensions

### Claim
A design claim is a testable statement about what the design will achieve. Not a description of what you're making â€” a statement about what will change.

- **â— Present**: "Parents will spend less time coordinating schedules"
- **â—‹ Missing**: "I'm designing a calendar app"

### Evidence
Evidence connects claims to reality. Observations, interviews, data â€” something outside your own assumptions.

- **â— Supported**: "In interviews, 8/10 parents mentioned coordination as their main frustration"
- **â—‹ Absent**: "I think parents are frustrated"

### Scope
Scope defines boundaries. Who is this for? Where does it apply? What's excluded?

- **â— Bounded**: "Working parents with children aged 6â€“12 in dual-income households"
- **â—‹ Unbounded**: "Parents" or "Everyone"

### Assumptions
Assumptions are beliefs you haven't verified. Acknowledging them is strength, not weakness.

- **â— Acknowledged**: "This assumes parents have smartphones and reliable internet"
- **â—‹ Hidden**: No mention of what must be true for the design to work

### Gaps
Gaps are logical jumps â€” places where reasoning skips steps between problem and solution.

- **â— Connected**: Clear path from research finding â†’ insight â†’ design decision
- **â—‹ Present**: "Users are frustrated, so I'm building a chatbot"

---

## API Endpoints

### `POST /analyse`

Analyse a design concept and return scores with diagnosis.

**Request:**
```json
{
  "concept": "Your design concept text here...",
  "include_diagnosis": true
}
```

**Response:**
```json
{
  "concept": "...",
  "scores": [
    {"dimension": "CLAIM", "confidence": 0.85, "severity": "SOLID", "display": "â— Present"},
    {"dimension": "EVIDENCE", "confidence": 0.32, "severity": "ATTENTION_NEEDED", "display": "â—‹ Absent â† Needs attention"}
  ],
  "evaluation": { ... },
  "diagnosis": "The concept states a clear claim about..."
}
```

### `POST /analyse/stream`

Same as above, but streams the diagnosis via Server-Sent Events.

---

## Stage 2 Rules

The judgment logic lives in `src/stage2_rules.py`. It's pure Python â€” no AI, no network calls, no randomness.

**Thresholds:**
```python
# Standard dimensions (high confidence = good)
THRESHOLD_SOLID = 0.8       # > 0.8 = SOLID
THRESHOLD_EXAMINE = 0.5     # 0.5â€“0.8 = WORTH_EXAMINING
                            # < 0.5 = ATTENTION_NEEDED

# GAPS has inverted polarity (high confidence = gaps present = bad)
GAPS_THRESHOLD_SOLID = 0.2      # < 0.2 = SOLID
GAPS_THRESHOLD_EXAMINE = 0.5    # 0.2â€“0.5 = WORTH_EXAMINING
                                # > 0.5 = ATTENTION_NEEDED
```

**Relationship rules:**
- Claim without evidence â†’ "You've made a claim but haven't shown how you know it's true"
- Evidence without claim â†’ "You've gathered evidence but haven't stated what you're claiming"
- Both missing â†’ "Neither a clear claim nor supporting evidence is present"

---

## Model Details

**Architecture:** DeBERTa-v3-base, fine-tuned for multi-label classification

**Training:**
- 5,600 annotated design concepts
- 5 binary labels (one per dimension)
- Validation accuracy: 98.38%

**Size:** ~738MB (model.safetensors: 705MB)

---

## Cost Analysis (Haiku Stage 3)

| Scale | Analyses/month | Cost |
|-------|----------------|------|
| Small class (25 Ã— 3) | 75 | â‚¹6 |
| Weekly (100/week) | 400 | â‚¹32 |
| Daily (100/day) | 3,000 | â‚¹240 |

---

## Licence

MIT â€” use it, modify it, ship it.

---

## Part of Koher

This tool demonstrates the Koher architecture. More tools ship monthly.

- **Website:** [koher.app](https://koher.app)
- **All tools:** [github.com/koher-architecture](https://github.com/koher-architecture)

*Built by [Prayas Abhinav](https://prayasabhinav.net)*
